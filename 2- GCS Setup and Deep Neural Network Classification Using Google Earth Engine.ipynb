{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ef91dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a88bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and Authenticating GEE Python API\n",
    "!pip install -U earthengine-api --no-deps --quiet\n",
    "import ee\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd66ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GCS Configuration\n",
    "PROJECT = 'your_google_cloud_console_project_name'\n",
    "REGION = 'your_google_cloud_storage_bucket_region'\n",
    "\n",
    "# Some Information about training data\n",
    "FEATURE_NAMES = ['B4','B3','B2','NDVI','LC']\n",
    "BANDS = ['B4','B3','B2','NDVI']\n",
    "LABEL = 'LC'\n",
    "N_CLASSES = 4 #Number of Classes\n",
    "\n",
    "# Imports (Training and Testing Data)\n",
    "TRAIN_FILE_PATH = 'training_data_path'\n",
    "TEST_FILE_PATH = 'testing_data_path'\n",
    "\n",
    "# (About Model that will later be exported)\n",
    "MODEL_DIR = 'gcs_bucket_path/Model_Folder_Name'\n",
    "MODEL_NAME = 'Model_Name'\n",
    "VERSION_NAME = 'V0' #Optional\n",
    "\n",
    "# Exported Image Detaiks\n",
    "EXPORTED_IMAGE_PREFIX = 'Image_Prefix_Name' #exported image from GEE JS API to GCS **Important**\n",
    "OUTPUT_IMAGE_FILE = 'gcs_bucket_dir/fileName.TFRecord'\n",
    "OUTPUT_ASSET_ID = 'projects/your_GEE_JS_API_Assets_project_name/assets/imageName'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927f690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset from the TFRecord file in Cloud Storage. (Prepare for TensorFlow)\n",
    "train_dataset = tf.data.TFRecordDataset(TRAIN_FILE_PATH, compression_type='GZIP')\n",
    "# Print the first record to check.\n",
    "iter(train_dataset).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d5cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of fixed-length features, all of which are float32.\n",
    "columns = [\n",
    "  tf.io.FixedLenFeature(shape=[1], dtype=tf.float32) for k in FEATURE_NAMES\n",
    "]\n",
    "\n",
    "\n",
    "# Dictionary with names as keys, features as values.\n",
    "features_dict = dict(zip(FEATURE_NAMES, columns))\n",
    "\n",
    "def parse_tfrecord(example_proto):\n",
    "  \"\"\"The parsing function.\n",
    "\n",
    "  Read a serialized example into the structure defined by featuresDict.\n",
    "\n",
    "  Args:\n",
    "    example_proto: a serialized Example.\n",
    "\n",
    "  Returns:\n",
    "    A tuple of the predictors dictionary and the label, cast to an `int32`.\n",
    "  \"\"\"\n",
    "  parsed_features = tf.io.parse_single_example(example_proto, features_dict)\n",
    "  labels = parsed_features.pop(LABEL)\n",
    "  return parsed_features, tf.cast(labels, tf.int32)\n",
    "\n",
    "# Map the function over the dataset.\n",
    "parsed_dataset = train_dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
    "\n",
    "# Print the first parsed record to check.\n",
    "iter(parsed_dataset).next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras requires inputs as a tuple.  Note that the inputs must be in the\n",
    "# right shape.  Also note that to use the categorical_crossentropy loss,\n",
    "# the label needs to be turned into a one-hot vector.\n",
    "def to_tuple(inputs, label):\n",
    "  return (tf.transpose(list(inputs.values())),\n",
    "          tf.one_hot(indices=label, depth=N_CLASSES))\n",
    "\n",
    "# Map the to_tuple function\n",
    "input_dataset = parsed_dataset.map(to_tuple)\n",
    "\n",
    "print(input_dataset,'Printed \\n \\n')\n",
    "iter(input_dataset).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c9d2dd",
   "metadata": {},
   "source": [
    "# Our Deep Neural Network Model Defind Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c39f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layers in the model.\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(N_CLASSES, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b682214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with the specified loss function.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059cbbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = input_dataset.shuffle(64).batch(8)\n",
    "iter(input_dataset).next() #printing the first training record just for check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f29309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "model.fit(x=input_dataset, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51183c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Summary and Saving the model\n",
    "model.summary()\n",
    "model.save(MODEL_DIR, save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aefcf1",
   "metadata": {},
   "source": [
    "# Accuracy Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d9e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK THE MODEL accuracy on the validation dataset\n",
    "test_dataset = (\n",
    "  tf.data.TFRecordDataset(TEST_FILE_PATH, compression_type='GZIP')\n",
    "    .map(parse_tfrecord, num_parallel_calls=5)\n",
    "    .map(to_tuple)\n",
    "    .batch(2))\n",
    "\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9829b1",
   "metadata": {},
   "source": [
    "# Loading the image dataset patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c6744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying The Image\n",
    "# We will now use the DNN model to predict the output class for all pixels of the input image.\n",
    "# The input composite for the entire basin has been exported to GCS. We will read the image and run prediction for each image path.\n",
    "# When you export an image from Earth Engine as TFRecords, you get 2 files\n",
    "# .tfrecord.gz files containing image patches\n",
    "# mixer.json file containing image metadata and georeferencing information\n",
    "\n",
    "# Get a list of all the files in the output bucket.\n",
    "files_list = !gsutil ls 'path_to_gcs_bucket'\n",
    "\n",
    "# Get only the files generated by the image export.\n",
    "exported_files_list = [s for s in files_list if EXPORTED_IMAGE_PREFIX in s]\n",
    "\n",
    "# Get the list of image files and the JSON mixer file.\n",
    "image_files_list = []\n",
    "json_file = None\n",
    "for f in exported_files_list:\n",
    "  if f.endswith('.tfrecord.gz'):\n",
    "    image_files_list.append(f)\n",
    "  elif f.endswith('.json'):\n",
    "    json_file = f\n",
    "\n",
    "print(image_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e94bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the files (patches) are in the right order.\n",
    "image_files_list.sort()\n",
    "image_files_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Load the contents of the mixer file to a JSON object.\n",
    "json_text = !gsutil cat {json_file}\n",
    "# Get a single string w/ newlines from the IPython.utils.text.SList\n",
    "mixer = json.loads(json_text.nlstr)\n",
    "mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9553fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevant info from the JSON mixer file.\n",
    "patch_width = mixer['patchDimensions'][0]\n",
    "patch_height = mixer['patchDimensions'][1]\n",
    "patches = mixer['totalPatches']\n",
    "patch_dimensions_flat = [patch_width * patch_height, 1]\n",
    "\n",
    "# Note that the tensors are in the shape of a patch, one patch for each band.\n",
    "image_columns = [\n",
    "  tf.io.FixedLenFeature(shape=patch_dimensions_flat, dtype=tf.float32)\n",
    "    for k in BANDS\n",
    "]\n",
    "\n",
    "# Parsing dictionary.\n",
    "image_features_dict = dict(zip(BANDS, image_columns))\n",
    "\n",
    "# Note that you can make one dataset from many files by specifying a list.\n",
    "image_dataset = tf.data.TFRecordDataset(image_files_list, compression_type='GZIP')\n",
    "\n",
    "# Parsing function.\n",
    "def parse_image(example_proto):\n",
    "  return tf.io.parse_single_example(example_proto, image_features_dict)\n",
    "\n",
    "# Parse the data into tensors, one long tensor per patch.\n",
    "image_dataset = image_dataset.map(parse_image, num_parallel_calls=5)\n",
    "\n",
    "# Break our long tensors into many little ones.\n",
    "image_dataset = image_dataset.flat_map(\n",
    "  lambda features: tf.data.Dataset.from_tensor_slices(features)\n",
    ")\n",
    "\n",
    "# Turn the dictionary in each record into a tuple without a label.\n",
    "image_dataset = image_dataset.map(\n",
    "  lambda data_dict: (tf.transpose(list(data_dict.values())), )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323700e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn each patch into a batch.\n",
    "image_dataset = image_dataset.batch(patch_width * patch_height)\n",
    "iter(image_dataset).next() #Display first record from batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction in batches, with as many steps as there are patches.\n",
    "predictions = model.predict(image_dataset, steps=patches, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf6460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the predictions come as a numpy array.  Check the first one.\n",
    "print(predictions[0])\n",
    "print(predictions[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the writer.\n",
    "writer = tf.io.TFRecordWriter(OUTPUT_IMAGE_FILE)\n",
    "\n",
    "# Every patch-worth of predictions we'll dump an example into the output\n",
    "# file with a single feature that holds our predictions. Since our predictions\n",
    "# are already in the order of the exported data, the patches we create here\n",
    "# will also be in the right order.\n",
    "patch = [[]]\n",
    "cur_patch = 1\n",
    "for prediction in predictions:\n",
    "  patch[0].append(int(tf.argmax(prediction, 1)))\n",
    "\n",
    "  # Once we've seen a patches-worth of class_ids...\n",
    "  if (len(patch[0]) == patch_width * patch_height):\n",
    "    print('Done with patch ' + str(cur_patch) + ' of ' + str(patches) + '...')\n",
    "    # Create an example\n",
    "    example = tf.train.Example(\n",
    "      features=tf.train.Features(\n",
    "        feature={\n",
    "          'prediction': tf.train.Feature(\n",
    "              int64_list=tf.train.Int64List(value=patch[0]))\n",
    "        }\n",
    "      )\n",
    "    )\n",
    "    # Write the example to the file and clear our patch array so it's ready for\n",
    "    # another batch of class ids\n",
    "    writer.write(example.SerializeToString())\n",
    "    patch = [[]]\n",
    "    cur_patch += 1\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a01aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload back to GEE\n",
    "!earthengine upload image --asset_id={OUTPUT_ASSET_ID} --pyramiding_policy=mode {OUTPUT_IMAGE_FILE} {json_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408947a7",
   "metadata": {},
   "source": [
    "My Special Thanks to Dr. Ujaval Gandhi (Spatial Thoughts) and Dr. Hammad Gilani (IWMI - Pakistan) for helping me learning the process.\n",
    "\n",
    "Watch the webinar here: https://www.youtube.com/watch?v=tCrM3Lm-AM4\n",
    "\n",
    "YouTube Link to my YouTube Channel: https://youtube.com/muddasirshah\n",
    "\n",
    "Email me at: muddasirshah@outlook.com\n",
    "\n",
    "Dr. Ujaval Gandhi:\n",
    "https://satialthoughts.com\n",
    "https://www.youtube.com/SpatialThoughts\n",
    "\n",
    "Some Useful Resources:\n",
    "\n",
    "https://developers.google.com/earth-engine/guides/tf_examples\n",
    "\n",
    "https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.14874&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e064b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
